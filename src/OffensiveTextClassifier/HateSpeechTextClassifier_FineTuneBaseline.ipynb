{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"OffensiveTextClassifier_FineTuneBaseline_Public.ipynb","provenance":[{"file_id":"1Sgdla1mwdG_nDjl7Vb8_hYoM7SlrDUPd","timestamp":1643525050416}],"collapsed_sections":["pLpZzfOIuw6p","F_CElTz_u01i","u0bWPaWlpT7E","hQum6lyTpXy5","E8qd0vkVwmcZ"],"mount_file_id":"1Sgdla1mwdG_nDjl7Vb8_hYoM7SlrDUPd","authorship_tag":"ABX9TyPECGi8M9Q6/j99CFPHuTS3"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Prepapre Env"],"metadata":{"id":"pLpZzfOIuw6p"}},{"cell_type":"code","metadata":{"id":"rbKBfZQO4pYr"},"source":["!pip install tensorflow_addons\n","!pip install transformers\n","!pip install sentencepiece\n","!pip install torchvision"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Prepare Workspace"],"metadata":{"id":"F_CElTz_u01i"}},{"cell_type":"code","metadata":{"id":"Zju5_kOy47q1"},"source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import ConfusionMatrixDisplay\n","from sklearn.model_selection import train_test_split\n","\n","from transformers import AlbertTokenizer, AlbertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n","from transformers import BertTokenizer, BertForSequenceClassification\n","\n","import pandas as pd\n","import numpy as np\n","from tqdm import trange\n","import matplotlib.pyplot as plt\n","% matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0YPF4msTlg4C"},"source":["tokenizer_model_name = 'bert-base-uncased'  # 'albert-large-v2', 'albert-base-v2'\n","WORKSPACE = 'drive/MyDrive/HushUp/OffensiveTextClassifier'\n","TEXT_MODEL_DIR = WORKSPACE + \"/Models/BERT_5\"\n","METADATA_FILE_PATH = WORKSPACE + '/compiled_data.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ppKKAqyqTclG"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u0bWPaWlpT7E"},"source":["# Data Preprocessing"]},{"cell_type":"code","metadata":{"id":"dwjdCv_rGCqu"},"source":["df = pd.read_csv(METADATA_FILE_PATH)\n","print(df.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NyNuZDQzCrZp"},"source":["y = df['Label']\n","X = df['Text']\n","\n","X_train, X_temp, y_train, y_temp = train_test_split(X,y,test_size=0.2, random_state=7, shuffle=True, stratify=y)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp,y_temp,test_size=0.5, random_state=7, shuffle=True, stratify=y_temp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MGGvYmLeDPlv"},"source":["print(\"Train shapes\")\n","print(X_train.shape)\n","print(y_train.shape)\n","\n","print(\"Test shapes\")\n","print(X_test.shape)\n","print(y_test.shape)\n","\n","print(\"Val shapes\")\n","print(X_val.shape)\n","print(y_val.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a7SyAyqr4eXs"},"source":["def load_data(sentences, labels=pd.Series([])):\n","    tokenizer = BertTokenizer.from_pretrained(tokenizer_model_name) # AlbertTokenizer.from_pretrained(tokenizer_model_name)\n","\n","    # Add special tokens at the beginning and end of each sentence\n","    sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n","    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","    MAX_LEN = 128\n","\n","    # convert the tokens to their index numbers\n","    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","    # Pad our input tokens\n","    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","    # Create attention masks\n","    attention_masks = []\n","\n","    # Create a mask of 1s for each token followed by 0s for padding\n","    for seq in input_ids:\n","        seq_mask = [float(i>0) for i in seq]\n","        attention_masks.append(seq_mask) \n","\n","    prediction_inputs = torch.tensor(input_ids)\n","    prediction_masks = torch.tensor(attention_masks)\n","    \n","    batch_size = 4  \n","\n","    if labels.empty:\n","      prediction_data = TensorDataset(prediction_inputs, prediction_masks)\n","      prediction_sampler = SequentialSampler(prediction_data)\n","      prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)   \n","    else:\n","      labels = [int(label) for label in labels]\n","      labels = torch.tensor(labels)\n","      prediction_data = TensorDataset(prediction_inputs, prediction_masks, labels)\n","      prediction_sampler = SequentialSampler(prediction_data)\n","      prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n","    return prediction_dataloader"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hQum6lyTpXy5"},"source":["# Fine Tunning"]},{"cell_type":"code","metadata":{"id":"xf5wAaBCmMK1"},"source":["# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r20Nmd45lwCw"},"source":["def fine_tune(X_train, y_train, X_val, y_val):\n","  model = BertForSequenceClassification.from_pretrained(TEXT_MODEL_DIR) # AlbertForSequenceClassification.from_pretrained(TEXT_MODEL_DIR)\n","  model.cuda() \n","\n","  train_dataloader = load_data(X_train,y_train)\n","  validation_dataloader  = load_data(X_val,y_val)\n","\n","  param_optimizer = list(model.named_parameters())\n","  no_decay = ['bias', 'gamma', 'beta']\n","  optimizer_grouped_parameters = [\n","      {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","      'weight_decay_rate': 0.01},\n","      {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","      'weight_decay_rate': 0.0}\n","  ]\n","\n","  # Parameters:\n","  lr = 2e-5\n","  max_grad_norm = 1.0\n","\n","  # Number of training epochs (authors recommend between 2 and 4)\n","  epochs = 4\n","\n","  num_training_steps = epochs * len(train_dataloader)\n","  num_warmup_steps = 200\n","\n","  optimizer = AdamW(optimizer_grouped_parameters, lr=lr, correct_bias=False)\n","  scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)\n","\n","  t = [] \n","\n","  # Store our loss and accuracy for plotting\n","  train_loss_set = []\n","  val_loss_set = []\n","\n","  # trange is a tqdm wrapper around the normal python range\n","  for _ in trange(epochs, desc=\"Epoch\"):\n","    # Training\n","    # Set our model to training mode (as opposed to evaluation mode)\n","    model.train()\n","    \n","    # Tracking variables\n","    tr_loss = 0\n","    \n","    # Train the data for one epoch\n","    for step, batch in enumerate(train_dataloader):\n","      # Add batch to GPU\n","      batch = tuple(t.to(device) for t in batch)\n","      # Unpack the inputs from our dataloader\n","      b_input_ids, b_input_mask, b_labels = batch\n","      # Clear out the gradients (by default they accumulate)\n","      optimizer.zero_grad()\n","      # Forward pass\n","      outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","      loss = outputs.loss\n","      train_loss_set.append(loss.item())    \n","      # Backward pass\n","      loss.backward()\n","      # Update parameters and take a step using the computed gradient\n","      torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)  # Gradient clipping is not in AdamW anymore (so you can use amp without issue)\n","      optimizer.step()\n","      scheduler.step()    \n","      \n","      # Update tracking variables\n","      tr_loss += loss.item()\n","\n","    print(\"Train loss: {}\".format(tr_loss/len(train_dataloader)))\n","      \n","      \n","    # Validation\n","    # Put model in evaluation mode to evaluate loss on the validation set\n","    model.eval()\n","\n","    # Tracking variables \n","    eval_loss, eval_accuracy = 0, 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","      # Add batch to GPU\n","      batch = tuple(t.to(device) for t in batch)\n","      # Unpack the inputs from our dataloader\n","      b_input_ids, b_input_mask, b_labels = batch\n","      # Telling the model not to compute or store gradients, saving memory and speeding up validation\n","      with torch.no_grad():\n","        # Forward pass, calculate logit predictions\n","        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","        logits = outputs.logits\n","        loss = outputs.loss\n","        val_loss_set.append(loss.item()) \n","      \n","      # Move logits and labels to CPU\n","      logits = logits.detach().cpu().numpy()\n","      label_ids = b_labels.to('cpu').numpy()\n","      # label_ids = b_labels.numpy()\n","\n","      tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","      \n","      eval_accuracy += tmp_eval_accuracy\n","      eval_loss += loss.item()\n","    print(\"Validation loss: {}\".format(eval_loss/len(validation_dataloader)))\n","\n","  print(\"Validation Accuracy: {}\".format(eval_accuracy/len(validation_dataloader)))\n","  return (model, train_loss_set, val_loss_set)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GxoJOTM7nJp5"},"source":["(model, train_loss_set, val_loss_set) = fine_tune(X_train, y_train, X_val, y_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.save_pretrained(WORKSPACE + \"/Models/BERT_fine_tune_5\")"],"metadata":{"id":"sA7EzImte6dt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.xlabel(\"Batch\")\n","plt.ylabel(\"Loss\")\n","plt.plot(train_loss_set, 'b-', label=\"Training loss\")\n","plt.plot(val_loss_set, 'g-', label=\"Validation loss\")\n","plt.show()"],"metadata":{"id":"Qsmx0T6Fd7nK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluate"],"metadata":{"id":"E8qd0vkVwmcZ"}},{"cell_type":"code","metadata":{"id":"s60AXGcI5e4A"},"source":["def get_predictions(model, sentences):\n","  # Put model in evaluation mode\n","  model.eval()\n","  predictions = []\n","  data_loader = load_data(sentences)\n","\n","  # Predict \n","  for batch in data_loader:\n","      batch = tuple(t.to(device) for t in batch)\n","\n","      # Unpack the inputs from our dataloader\n","      b_input_ids, b_input_mask = batch\n","\n","      # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n","      with torch.no_grad():\n","          # Forward pass, calculate logit predictions\n","          outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, return_dict=True)\n","          logits = outputs.logits  \n","\n","      # Move logits and labels to CPU\n","      logits = logits.detach().cpu().numpy()\n","\n","      # Store predictions and true labels\n","      predictions.extend(np.argmax(logits, axis=1))\n","  return predictions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fvaik_T3HBWP"},"source":["predictions = get_predictions(model,X_test)\n","print(len(predictions))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ICzzlcFHGNPb"},"source":["report = classification_report(y_test, predictions, zero_division=0)\n","print(report)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wYzuHMySHTCO"},"source":["cm = confusion_matrix(y_test, predictions, labels=[0,1])\n","ConfusionMatrixDisplay(cm, display_labels=[\"non-offensive\",\"offensive\"]).plot(values_format='')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U0f99neDZ8yo"},"source":["incorrect_predictions_df = pd.DataFrame()\n","i = 0\n","for (index,true_label) in y_test.iteritems():\n","  if true_label != predictions[i]:\n","    incorrect_predictions_df = incorrect_predictions_df.append(df.iloc[index])\n","  i += 1\n","    \n"," print(incorrect_predictions_df.shape)  "],"execution_count":null,"outputs":[]}]}